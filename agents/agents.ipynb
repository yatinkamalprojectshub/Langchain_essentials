{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75aa9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740cb80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, docs_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc4c7723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f80117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001F5D5349160>, search_kwargs={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200).split_documents(docs)\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "vectordb = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vectordb.as_retriever()\n",
    "retriever\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f9b449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tool to retrieval of all documents\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever,\"langsmith_search\",\"search for information about langsmith. for any question about langsmith you must use this tool\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c8cb0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='langsmith_search', description='search for information about langsmith. for any question about langsmith you must use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001F5FDC847C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001F5D5349160>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001F5FDC84900>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001F5D5349160>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c443d95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, docs_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c0d89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "788923d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'e:\\\\LANGCHAIN REBUILT\\\\venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " Tool(name='langsmith_search', description='search for information about langsmith. for any question about langsmith you must use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001F5FDC847C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001F5D5349160>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001F5FDC84900>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001F5D5349160>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf422ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from dotnet import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenaAI\n",
    "\n",
    "llm = ChatOpenaAI(model = \"gpt-3.5-turbo-0125\", temperature =0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b1115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from langchain import hub\n",
    "#get the prompt to use - can be modifiedd\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### agents are used to use a language model to chooose a sequence of actions to take. Language model is used as a reasoning agent to determine which actions to take and in which order\n",
    "#from langchain.agents import create_openai_tools_agent\n",
    "#agent = create_openai_tools_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## agent executer\n",
    "\"\"\"\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools,verbose=True)\n",
    "agent_executor\n",
    "agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ea86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "agent_executor.invoke({\"input\":\"Tell me about MAchineLearning\"})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcd9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m To find information about LangSmith, I should use the retriever tool. The input for the retriever tool can be a specific query related to LangSmith.\n",
      "\n",
      "Action: retriever\n",
      "Action Input: {'query': 'LangSmith'}\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mGet started with LangSmith - Docs by LangChainDocs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewQuickstartsTrace an applicationEvaluate an applicationTest promptsAPI & SDKsAPI referencePython SDKJS/TS SDKPricingPlansPricing FAQDocs by LangChain home pagePythonSearch...⌘KAsk AIGitHubForumForumSearch...NavigationGet started with LangSmithGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumGet started with LangSmithCopy pageCopy pageLangSmith is a platform for building production-grade LLM applications. Monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "LangSmith is framework agnostic — you can use it with or without LangChain’s open source frameworks langchain and langgraph.\n",
      "\n",
      "Start tracingGain visibility into each step your application takes when handling a request to debug faster.Learn moreEvaluate your applicationMeasure quality of your applications over time to build more reliable AI applications.Learn moreTest your promptsIterate on prompts, with automatic version control and collaboration features.Learn moreSet up your workspaceSet up your workspace, configure admin settings, and invite your team to collaborate.Learn moreTrace an applicationAssistantResponses are generated using AI and may contain mistakes.Docs by LangChain home pagegithubxlinkedinyoutubeResourcesChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Based on the information obtained from the retriever tool, LangSmith is a platform for building production-grade Language Model (LLM) applications. It provides observability and evaluation features to help developers monitor, evaluate, and test their applications. LangSmith is framework agnostic, meaning it can be used with or without LangChain's open source frameworks langchain and langgraph.\n",
      "\n",
      "Final Answer: LangSmith is a platform for building production-grade LLM applications that offers observability, evaluation, and testing features. It is framework agnostic and can be used with or without LangChain’s open source frameworks langchain and langgraph.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final Answer: LangSmith is a platform for building production-grade LLM applications that offers observability, evaluation, and testing features. It is framework agnostic and can be used with or without LangChain’s open source frameworks langchain and langgraph.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.agents import Tool\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"mistral\", temperature=0)\n",
    "\n",
    "tools = [\n",
    "    Tool(name=\"arxiv\", func=arxiv.run, description=\"Research papers\"),\n",
    "    Tool(name=\"wiki\", func=wiki.run, description=\"Wikipedia queries\"),\n",
    "    Tool(name=\"retriever\", func=retriever_tool.run, description=\"LangSmith queries\"),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  #weaker than OpenAI but Mistral-friendly because I dont have PAISA\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = agent.run(\"Tell me about LangSmith\")\n",
    "print(\"Final Answer:\", response)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "agent_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an intelligent assistant with access to tools.\n",
    "\n",
    "TOOLS:\n",
    "- arxiv: use for research papers.\n",
    "- wiki: use for Wikipedia queries.\n",
    "- retriever: use for LangSmith related queries.\n",
    "\n",
    "When deciding, follow this format strictly:\n",
    "Thought: reason about what to do\n",
    "Action: tool name (one of [arxiv, wiki, retriever])\n",
    "Action Input: the input to the tool\n",
    "Observation: the tool's result\n",
    "Final Answer: the final response to the user\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e95cbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m To answer this question, I will use a combination of resources. First, I'll look up an overview of machine learning on Wikipedia to get a general understanding. Then, I'll search for research papers related to machine learning to delve deeper into the subject.\n",
      "\n",
      "Action: wiki\n",
      "Action Input: Machine Learning\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\n",
      "ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\n",
      "Statistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning. \n",
      "From a theoretical viewpoint, probably approximately correct learning provides a framework for describing machine learning.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now that I have an overview of machine learning from Wikipedia, I will search for research papers related to machine learning to delve deeper into the subject.\n",
      "\n",
      "Action: arxiv\n",
      "Action Input: Machine Learning\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2019-09-08\n",
      "Title: Lecture Notes: Optimization for Machine Learning\n",
      "Authors: Elad Hazan\n",
      "Summary: Lecture notes on optimization for machine learning, derived from a course at\n",
      "Princeton University and tutorials given in MLSS, Buenos Aires, as well as\n",
      "Simons Foundation, Berkeley.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Machine Learning is a field of study in artificial intelligence that focuses on the development and study of statistical algorithms that can learn from data and generalize to unseen data. It finds application in various fields such as natural language processing, computer vision, speech recognition, agriculture, medicine, and business problems known as predictive analytics. The foundations of machine learning are statistics and mathematical optimization methods. A research paper titled \"Lecture Notes: Optimization for Machine Learning\" by Elad Hazan provides a deeper understanding of the subject.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final Answer: Machine Learning is a field of study in artificial intelligence that focuses on the development and study of statistical algorithms that can learn from data and generalize to unseen data. It finds application in various fields such as natural language processing, computer vision, speech recognition, agriculture, medicine, and business problems known as predictive analytics. The foundations of machine learning are statistics and mathematical optimization methods. A research paper titled \"Lecture Notes: Optimization for Machine Learning\" by Elad Hazan provides a deeper understanding of the subject.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"Tell me about Machine Learning\")\n",
    "print(\"Final Answer:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69726a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ZERO_SHOT_REACT_DESCRIPTION\n",
    "\n",
    "It’s one of the built-in agent types in LangChain.\n",
    "\n",
    "Zero-shot → means the model is not trained on your tools beforehand; it figures out which tool to call just from the tool descriptions you give.\n",
    "\n",
    "ReAct → stands for Reasoning + Acting. The model doesn’t just directly answer, it follows a loop:\n",
    "\n",
    "Reason about the question (decides what tool is needed).\n",
    "\n",
    "Act by calling a tool (e.g., search, math, retriever).\n",
    "\n",
    "Looks at the tool output.\n",
    "\n",
    "Decides next step until it has a final answer.\n",
    "\n",
    "Description → it uses the tool descriptions you provide to decide when and how to use them.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f7506e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
